# ğŸ§ Whisper Batch Transcriber

**Version 1.1 â€” CUDA + DirectML Edition**  
Created by **Simon Matthew Payne (2025)**

A simple, one-click desktop app that automatically transcribes any audio or video file using [OpenAI Whisper](https://github.com/openai/whisper).  
Runs **entirely offline**, supports **NVIDIA (CUDA)**, **AMD & Intel (DirectML)**, or **CPU**, and saves plain-text transcripts next to your originals.  

---

## ğŸš€ Quick Start

# Whisper Batch Transcriber

Offline-ready batch audio-to-text transcriber built with [OpenAI Whisper](https://github.com/openai/whisper).

---

## ğŸ”§ Rebuilding the App

1. **Download both files**:
   - `WhisperBatchTranscriber_part1.bin` https://github.com/simonmatthewpayne/Batch-Transcriber/releases/download/untagged-7600cffb1c97574dcf58/WhisperBatchTranscriber_part1.bin
   - `WhisperBatchTranscriber_part2.bin` https://github.com/simonmatthewpayne/Batch-Transcriber/releases/download/untagged-7600cffb1c97574dcf58/WhisperBatchTranscriber_part2.bin

2. **Place them in the same folder** as `reassemble.bat` https://github.com/simonmatthewpayne/Batch-Transcriber/releases/download/untagged-7600cffb1c97574dcf58/reassemble.bat.

3. **Double-click `reassemble.bat`** â€” it will rebuild:

3. **Double-click `WhisperBatchTranscriber.exe`**  
4. Click **Select files â€¦**, choose one or many audio/video files.  
   - Supported: `mp3`, `wav`, `m4a`, `flac`, `aac`, `ogg`, `opus`, `wma`, `mp4`, `mkv`, `mov`, `avi`, `webm`, and more.  
5. Leave **Model** and **Device** on â€œAutoâ€ (recommended).  
   - The app detects your GPU and chooses a sensible model size automatically.  
6. Click **Run** to start transcribing.  
7. When finished, youâ€™ll find a `*_transcript.txt` next to each original file.

---

## ğŸ§  Features

| Capability | Description |
|-------------|-------------|
| ğŸï¸ **Batch processing** | Transcribe many files at once. |
| âš™ï¸ **Auto hardware detection** | CUDA â†’ DirectML â†’ CPU fallback chain. |
| ğŸ’¡ **Model recommendations** | Chooses `tiny / base / small / medium / large` based on VRAM and RAM. |
| ğŸ”„ **Cancel controls** | Cancel selected pending files or stop after current file safely. |
| ğŸ“Š **Progress bar + status** | See which file is running and how many are done. |
| ğŸ§© **Bundled FFmpeg** | Works out of the box â€” no extra downloads. |
| ğŸ’¾ **Offline & private** | All transcription happens locally on your machine. |

---

## âš™ï¸ System Requirements

| Component | Minimum | Recommended |
|------------|----------|-------------|
| OS | Windows 10 / 11 (64-bit) | Latest Windows 11 |
| RAM | 8 GB | 16 GB + |
| GPU | Optional | NVIDIA GPU (CUDA) / AMD or Intel GPU (DirectML) |

### GPU acceleration details

| Vendor | Backend | Support |
|---------|----------|----------|
| **NVIDIA (GeForce / RTX)** | CUDA (Pytorch) | âœ… Full speed |
| **AMD (Radeon)** | DirectML (Windows only) | âš™ï¸ Moderate speed |
| **Intel (iGPU / Arc)** | DirectML (Windows only) | âš™ï¸ Moderate speed |
| **No GPU** | CPU | ğŸ¢ Works (but slower) |

> The app automatically picks the best available backend.  
> No manual driver configuration required.

---

## ğŸ§© Troubleshooting

**â€œffmpeg not foundâ€**  
> Shouldnâ€™t happen â€” ffmpeg is bundled. If it does, ensure `ffmpeg/ffmpeg.exe` exists next to the EXE.

**â€œCUDA not availableâ€**  
> You donâ€™t have an NVIDIA GPU or drivers installed.  
> The app will use DirectML or CPU automatically.

**â€œSlow performanceâ€**  
> Try a smaller model (`base` or `tiny`) or ensure GPU acceleration is enabled (auto by default).

---

## âš–ï¸ Licences & Acknowledgements

- ğŸ§  **Whisper** â€” Â© OpenAI (MIT License)  
- ğŸ”¥ **PyTorch** â€” Â© Meta AI (BSD License)  
- ğŸ¬ **FFmpeg** â€” LGPL/GPL License (https://ffmpeg.org/)  
  - See `FFMPEG_LICENSE.txt` for licence text.  
- ğŸª„ **torch-directml** â€” Â© Microsoft (DirectML backend for PyTorch)

---

## ğŸ’¬ Credits

Developed by **Simon Matthew Payne**, PhD in Condensed Matter Physics  
University of Bristol  Â· 2025  

> _â€œEasy-mode transcription for everyone â€” just drag, drop, and go.â€_
